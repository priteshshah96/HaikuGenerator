{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning For Haikugen project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Text preprocessing and modelling\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                0                      1                 2  \\\n",
      "0           0    fishing boats              colors of       the rainbow   \n",
      "1           1  ash wednesday--    trying to remember           my dream   \n",
      "2           2     snowy morn--    pouring another cup   of black coffee   \n",
      "3           3     shortest day           flames dance       in the oven   \n",
      "4           4             haze  half the horse hidden  behind the house   \n",
      "\n",
      "        source                                     hash  \n",
      "0  tempslibres           FISHINGBOATSCOLORSOFTHERAINBOW  \n",
      "1  tempslibres      ASHWEDNESDAYTRYINGTOREMEMBERMYDREAM  \n",
      "2  tempslibres  SNOWYMORNPOURINGANOTHERCUPOFBLACKCOFFEE  \n",
      "3  tempslibres          SHORTESTDAYFLAMESDANCEINTHEOVEN  \n",
      "4  tempslibres     HAZEHALFTHEHORSEHIDDENBEHINDTHEHOUSE  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/all_haiku.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     combined_haiku  \\\n",
      "0               fishing boats colors of the rainbow   \n",
      "1      ash wednesday-- trying to remember  my dream   \n",
      "2  snowy morn-- pouring another cup of black coffee   \n",
      "3             shortest day flames dance in the oven   \n",
      "4       haze half the horse hidden behind the house   \n",
      "\n",
      "                                  processed_haiku  \n",
      "0             fishing boats colors of the rainbow  \n",
      "1      ash wednesday trying to remember  my dream  \n",
      "2  snowy morn pouring another cup of black coffee  \n",
      "3           shortest day flames dance in the oven  \n",
      "4     haze half the horse hidden behind the house  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "  # To ensure text is a string and removing Special Characters\n",
    "    if isinstance(text, str):\n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    else:\n",
    "        text = np.nan\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['combined_haiku'] = df['0'].astype(str) + ' ' + df['1'].astype(str) + ' ' + df['2'].astype(str)\n",
    "\n",
    "#preprocessing to each combined haiku\n",
    "df['processed_haiku'] = df['combined_haiku'].apply(preprocess_text)\n",
    "\n",
    "# Dropping rows with NaN \n",
    "df.dropna(subset=['processed_haiku'], inplace=True)\n",
    "\n",
    "print(df[['combined_haiku', 'processed_haiku']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144123, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.85, max_features=5000, stop_words='english')\n",
    "\n",
    "# Fit and transform the processed haikus into vectors\n",
    "tfidf_matrix = vectorizer.fit_transform(df['processed_haiku'])\n",
    "\n",
    "print(tfidf_matrix.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tfidf matrix is huge, so here i have created a represention of haikus using Word Embeddings. I have used the Word2Vec model from the gensim library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words='english')\n",
    "# Fit and transform the processed haikus\n",
    "word_count_matrix = vectorizer.fit_transform(df['processed_haiku'])\n",
    "# Convert the word count matrix to a DataFrame\n",
    "word_count_df = pd.DataFrame(word_count_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Saving to Csv\n",
    "word_count_df.to_csv('dataset/word_count_matrix.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "df['tokenized_haiku'] = df['processed_haiku'].apply(lambda x: x.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have loaded the Word2vec pretrained model from google\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('genmi/GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
    "    if len(tokens_list) < 1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "df['word2vec_vector'] = df['tokenized_haiku'].apply(lambda x: get_average_word2vec(x, word2vec_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>source</th>\n",
       "      <th>hash</th>\n",
       "      <th>combined_haiku</th>\n",
       "      <th>processed_haiku</th>\n",
       "      <th>tokenized_haiku</th>\n",
       "      <th>word2vec_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fishing boats</td>\n",
       "      <td>colors of</td>\n",
       "      <td>the rainbow</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>FISHINGBOATSCOLORSOFTHERAINBOW</td>\n",
       "      <td>fishing boats colors of the rainbow</td>\n",
       "      <td>fishing boats colors of the rainbow</td>\n",
       "      <td>[fishing, boats, colors, of, the, rainbow]</td>\n",
       "      <td>[0.06935628255208333, 0.11063639322916667, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ash wednesday--</td>\n",
       "      <td>trying to remember</td>\n",
       "      <td>my dream</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>ASHWEDNESDAYTRYINGTOREMEMBERMYDREAM</td>\n",
       "      <td>ash wednesday-- trying to remember  my dream</td>\n",
       "      <td>ash wednesday trying to remember  my dream</td>\n",
       "      <td>[ash, wednesday, trying, to, remember, my, dream]</td>\n",
       "      <td>[0.09874834333147321, 0.00020926339285714285, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>snowy morn--</td>\n",
       "      <td>pouring another cup</td>\n",
       "      <td>of black coffee</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>SNOWYMORNPOURINGANOTHERCUPOFBLACKCOFFEE</td>\n",
       "      <td>snowy morn-- pouring another cup of black coffee</td>\n",
       "      <td>snowy morn pouring another cup of black coffee</td>\n",
       "      <td>[snowy, morn, pouring, another, cup, of, black...</td>\n",
       "      <td>[-0.02301025390625, 0.065765380859375, -0.0730...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>shortest day</td>\n",
       "      <td>flames dance</td>\n",
       "      <td>in the oven</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>SHORTESTDAYFLAMESDANCEINTHEOVEN</td>\n",
       "      <td>shortest day flames dance in the oven</td>\n",
       "      <td>shortest day flames dance in the oven</td>\n",
       "      <td>[shortest, day, flames, dance, in, the, oven]</td>\n",
       "      <td>[0.04017857, -0.027413504, 0.06512451, 0.06622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>haze</td>\n",
       "      <td>half the horse hidden</td>\n",
       "      <td>behind the house</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>HAZEHALFTHEHORSEHIDDENBEHINDTHEHOUSE</td>\n",
       "      <td>haze half the horse hidden behind the house</td>\n",
       "      <td>haze half the horse hidden behind the house</td>\n",
       "      <td>[haze, half, the, horse, hidden, behind, the, ...</td>\n",
       "      <td>[0.11157799, 0.04814911, 0.011920929, 0.004920...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                0                      1                 2  \\\n",
       "0           0    fishing boats              colors of       the rainbow   \n",
       "1           1  ash wednesday--    trying to remember           my dream   \n",
       "2           2     snowy morn--    pouring another cup   of black coffee   \n",
       "3           3     shortest day           flames dance       in the oven   \n",
       "4           4             haze  half the horse hidden  behind the house   \n",
       "\n",
       "        source                                     hash  \\\n",
       "0  tempslibres           FISHINGBOATSCOLORSOFTHERAINBOW   \n",
       "1  tempslibres      ASHWEDNESDAYTRYINGTOREMEMBERMYDREAM   \n",
       "2  tempslibres  SNOWYMORNPOURINGANOTHERCUPOFBLACKCOFFEE   \n",
       "3  tempslibres          SHORTESTDAYFLAMESDANCEINTHEOVEN   \n",
       "4  tempslibres     HAZEHALFTHEHORSEHIDDENBEHINDTHEHOUSE   \n",
       "\n",
       "                                     combined_haiku  \\\n",
       "0               fishing boats colors of the rainbow   \n",
       "1      ash wednesday-- trying to remember  my dream   \n",
       "2  snowy morn-- pouring another cup of black coffee   \n",
       "3             shortest day flames dance in the oven   \n",
       "4       haze half the horse hidden behind the house   \n",
       "\n",
       "                                  processed_haiku  \\\n",
       "0             fishing boats colors of the rainbow   \n",
       "1      ash wednesday trying to remember  my dream   \n",
       "2  snowy morn pouring another cup of black coffee   \n",
       "3           shortest day flames dance in the oven   \n",
       "4     haze half the horse hidden behind the house   \n",
       "\n",
       "                                     tokenized_haiku  \\\n",
       "0         [fishing, boats, colors, of, the, rainbow]   \n",
       "1  [ash, wednesday, trying, to, remember, my, dream]   \n",
       "2  [snowy, morn, pouring, another, cup, of, black...   \n",
       "3      [shortest, day, flames, dance, in, the, oven]   \n",
       "4  [haze, half, the, horse, hidden, behind, the, ...   \n",
       "\n",
       "                                     word2vec_vector  \n",
       "0  [0.06935628255208333, 0.11063639322916667, 0.0...  \n",
       "1  [0.09874834333147321, 0.00020926339285714285, ...  \n",
       "2  [-0.02301025390625, 0.065765380859375, -0.0730...  \n",
       "3  [0.04017857, -0.027413504, 0.06512451, 0.06622...  \n",
       "4  [0.11157799, 0.04814911, 0.011920929, 0.004920...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpvenv",
   "language": "python",
   "name": "nlpvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
